# Cache IV

*December 8, 2024*

## Set-Associative Caches

内存地址字段中的标签和偏移量和直接映射缓存是一样的，但是**索引字段指向一组块**而不是一个块了。

每个组有 N 个块，则称为 N 路组相联缓存（N-Way Set Associative Cache）。

对于给定的内存地址：

- 通过索引字段找到正确的组
- 将地址标签字段与组中所有块的标签进行比较
- 如果有一个相匹配，则是命中；否则未命中
- 最后通过偏移量字段来找到块中需要的数据

优点：

- 即便是2路组相联缓存也能避免大量的冲突未命中
- 硬件成本是不很高：只需要N个比较器

事实上，对于一个有M个块的缓存：

- 如果它是1路组相联，其实就是**直接映射**缓存
- 如果它是 M 路组相联，其实就是**全相联**缓存

所以这两种类别其实只是更普遍的组相联的特殊情况。

4路组相联缓存电路图：

![[4-Way Set Associative Cache Circuit.png|500]]

## Block Replacement

1. 最少最近使用（Least Recently Used，LRU）
	- 想法：淘汰最近被访问（读取或写入）次数最少的块
	- 好处：
		- **时间局部性**：最近的使用暗示着未来可能的使用
		- 事实上这是一种很有效的策略
	- 缺点：
		- 对于2路组相联，很容易跟踪（$2!=2^1$，一个LRU位e）
		- 对于4路及以上的组相联，需要复杂的硬件和更多的时间跟踪
1. 先进先出（FIFO）
	- 想法：忽略访问，只跟踪被初始化的顺序
2. 随机（Random）
	- 如果时间局部性较低，则表现不错

## Average Memory Access Time (AMAT)

从低一层访问内存的平均时间：

$$
平均内存访问时间= 命中时间 + 未命中惩罚 * 未命中率
$$

缓存营造了一个有很大、便宜并且快速的内存的假象（平均来说）。

降低未命中率的方法：

- 更大的缓存
	- 受成本和技术的限制
	- 一级缓存的命中时间小于时钟周期（更大的缓存速度更慢）
- 提高关联性：在缓存中为每个内存块提供更多的空间
	- 全相联
		- 每个内存块可以在缓存的任意条目
	- N路组相联
		- 每个内存块有N个位置
		- 直接映射：$N=1$ 

多级缓存层次结构可以进一步降低未命中惩罚，从而降低平均内存访问时间

### Great Idea #3: Principle of Locality / Memory Hierarchy

![[Memory Hierarchy.png]]